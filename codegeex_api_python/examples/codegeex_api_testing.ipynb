{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd92436",
   "metadata": {},
   "source": [
    "Ref:  \n",
    "- [LLMs: Get predictions from a language model](https://python.langchain.com/en/latest/getting_started/getting_started.html#llms-get-predictions-from-a-language-model)\n",
    "- [A simple guide to setting the GPT-3 temperature](https://algowriting.medium.com/gpt-3-temperature-setting-101-41200ff0d0be)\n",
    "- [HumanEval-X: A new benchmark for Multilingual Program Synthesis](https://github.com/THUDM/CodeGeeX/blob/main/codegeex/benchmark/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcf5da",
   "metadata": {},
   "source": [
    "## Import HumanEval-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9736d9-2761-4995-8fdd-85a7c42ed36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpp:  164 taske(s), elapsed_time: 2995.141745413188 S, 49.9190290902198 minutes, 0.8319838181703301 hours.\n",
    "# java: 164 taske(s), elapsed_time: 4135.389279692899 S, 68.92315466154832 minutes, 1.1487192443591387 hours.\n",
    "# python: 164 taske(s), elapsed_time: 7769.483070801012 S, 129.4913845133502 minutes, 2.15818974188917 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = ('cpp', 'java', 'python')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea86e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b75c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('.').resolve().parents[0]))\n",
    "\n",
    "from codegeex_api import CodeGeeX\n",
    "from codegeex_utility import stream_jsonl_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706913c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "manage_properties = dict([\n",
    "        (line.split('=')[0], line.split('=')[1].strip())\n",
    "            for line in open(f'../../manage.properties')])\n",
    "\n",
    "print(json.dumps(manage_properties, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659112ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Human Evalu Python\n",
    "HEP_FILE = os.path.join(\n",
    "        manage_properties['CodeGeeX_home'],\n",
    "        f'codegeex/benchmark/humaneval-x/{language}' \\\n",
    "                f'/data/humaneval_{language}.jsonl.gz')\n",
    "assert os.path.exists(HEP_FILE)\n",
    "\n",
    "HEP = stream_jsonl_all(HEP_FILE)\n",
    "\n",
    "print(len(HEP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1978d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = HEP[0]['task_id'].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efecfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = HEP[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d3e7b",
   "metadata": {},
   "source": [
    "## Ask CodeGeeX to generate code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a5a55",
   "metadata": {},
   "source": [
    "#### <font size=\"7\" color=\"orange\">âš </font> Do <span style=\"color:red\">NOT</span> submit the config file to GitHub because of security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "codegeex_api_config = json.load(\n",
    "        open('codegeex_api_config.json', 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "codegeex_api_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68be839-09af-4c91-a600-6621d2ac6425",
   "metadata": {},
   "source": [
    "**For \"1.x.x.x\", return string; for \"2.x.x.x\", return json.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c24a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CodeGeeX(codegeex_api_config)  # model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c288e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_return = m(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7f35c-0ea8-4c7c-91e7-0ab96247a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(m_return, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9d90b-0c3b-429f-a6a8-b4af817cd0ef",
   "metadata": {},
   "source": [
    "**temperature & top_p**  \n",
    "\n",
    "Ref:  \n",
    "- Zheng, Q., Xia, X., Zou, X., Dong, Y., Wang, S., Xue, Y., Wang, Z., Shen, L., Wang, A., Li, Y. and Su, T., 2023. Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x. *arXiv preprint arXiv:2303.17568*.\n",
    "\n",
    "#### 4.1 Evaluation Settings\n",
    "Page 11:\n",
    "\n",
    "*For CodeGeeX in code generation, we use t = 0:2; p = 0:95 for pass@1 and\n",
    "t = 0:8; p = 0:95 for pass@10 and pass@100 (except for Go and JavaScript, where p = 0:9).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad71875-de2a-44b8-a018-526c18ed7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_return = m(PROMPT, temperature=0.2, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffd203-16ac-418e-85f2-a59fc8de5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(m_return, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b49092-f5d9-46fd-9680-a8166e554d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose=True will let more info print out to the sever's stderr.\n",
    "# However, client will not get these info.\n",
    "\n",
    "m_return = m(PROMPT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df048-f24a-4517-92ec-c858f37e4f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(m_return, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832a68f-c2a0-4b90-a6f2-d0d26574b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_return['stdout'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8749d-afdd-4736-90f3-0f68e66d1cf3",
   "metadata": {},
   "source": [
    "**Run 164 and write to jsonl file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec47126-abff-4b47-8a6f-1ed36f4a2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dae08-70a9-4b58-9ff9-5cc952699cbe",
   "metadata": {},
   "source": [
    " JSON list format. Ref: https://github.com/THUDM/CodeGeeX/blob/main/codegeex/benchmark/README.md#evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f6de3-626a-469e-bd72-a6cd9296d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'results/{language}_t02_p095_{datetime.datetime.now()}' \\\n",
    "        .replace(':', '').replace('-', '').replace('.', '_').replace(' ', '_') \\\n",
    "        + '.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d6de8-cb86-438d-af70-30a7dfbf2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18cf8d-c756-4085-83fb-066c9d288d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca23c2-ac04-4415-9cd9-bda55ed5609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.perf_counter()\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "    for i in HEP:\n",
    "        print(i['task_id'], end='\\t')\n",
    "        \n",
    "        # Generate code\n",
    "        # use t = 0:2; p = 0:95 for pass@1\n",
    "        m_return = m(i['prompt'], temperature=0.2, top_p=0.95)\n",
    "        \n",
    "        line = {\n",
    "            'task_id': i['task_id'],\n",
    "            'prompt': i['prompt'],\n",
    "            'generation': m_return['stdout'][0].replace('<|endoftext|>', '')\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "\n",
    "et = time.perf_counter()\n",
    "elapsed_time = et - st\n",
    "print(f'\\n{len(HEP)} taske(s), elapsed_time: ' \\\n",
    "        f'{elapsed_time} S, {elapsed_time/60} minutes, {elapsed_time/60/60} hours.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5168ca4-0502-4594-8776-86d096b43265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
